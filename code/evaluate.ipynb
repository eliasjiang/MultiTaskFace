{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve,\n",
    "    confusion_matrix, roc_auc_score, roc_curve, average_precision_score\n",
    ")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, device, pos_label=1):\n",
    "    \"\"\"\n",
    "    评估二分类模型性能\n",
    "\n",
    "    :param model: 训练好的模型\n",
    "    :param data_loader: 数据加载器\n",
    "    :param device: 设备（CPU 或 GPU）\n",
    "    :param pos_label: 正类标签，默认为 1\n",
    "    :return: 评估结果字典\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(features)\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(probs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "    # 计算评估指标\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(all_targets, all_preds),\n",
    "        'precision': precision_score(all_targets, all_preds, pos_label=pos_label),\n",
    "        'recall': recall_score(all_targets, all_preds, pos_label=pos_label),\n",
    "        'f1': f1_score(all_targets, all_preds, pos_label=pos_label),\n",
    "        'confusion_matrix': confusion_matrix(all_targets, all_preds).tolist(),\n",
    "        'roc_auc': roc_auc_score(all_targets, all_probs) if len(set(all_targets)) > 1 else None,\n",
    "        'mAP': average_precision_score(all_targets, all_probs),\n",
    "        'fpr': None,\n",
    "        'tpr': None,\n",
    "        'precision_curve': None,\n",
    "        'recall_curve': None\n",
    "    }\n",
    "\n",
    "    # 计算 FPR 和 TPR\n",
    "    if metrics['roc_auc'] is not None:\n",
    "        fpr, tpr, _ = roc_curve(all_targets, all_probs, pos_label=pos_label)\n",
    "        metrics['fpr'] = fpr\n",
    "        metrics['tpr'] = tpr\n",
    "\n",
    "    # 计算 Precision-Recall 曲线\n",
    "    precision, recall, _ = precision_recall_curve(all_targets, all_probs, pos_label=pos_label)\n",
    "    metrics['precision_curve'] = precision\n",
    "    metrics['recall_curve'] = recall\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_final(model, data_loader, device, pos_label=1):\n",
    "    \"\"\"\n",
    "    评估模型性能，包括详细指标\n",
    "\n",
    "    :param model: 训练好的模型\n",
    "    :param data_loader: 数据加载器\n",
    "    :param device: 设备（CPU 或 GPU）\n",
    "    :param pos_label: 正类标签，默认为 1\n",
    "    :return: 评估结果字典\n",
    "    \"\"\"\n",
    "    metrics = evaluate_model(model, data_loader, device, pos_label)\n",
    "\n",
    "    # 打印评估结果\n",
    "    print(f'Evaluation for model: {model.__class__.__name__}')\n",
    "    print(f'{{')\n",
    "    print(f'    Accuracy: {metrics[\"accuracy\"] * 100:.2f}%')\n",
    "    print(f'    Precision: {metrics[\"precision\"]:.2f}')\n",
    "    print(f'    Recall: {metrics[\"recall\"]:.2f}')\n",
    "    print(f'    F1 Score: {metrics[\"f1\"]:.2f}')\n",
    "    print(f'    Confusion Matrix: {metrics[\"confusion_matrix\"]}')\n",
    "    print(f'    ROC AUC: {metrics[\"roc_auc\"]:.2f}')\n",
    "    print(f'    mAP: {metrics[\"mAP\"]:.2f}')\n",
    "    print(f'}}')\n",
    "\n",
    "    # 绘制 ROC 曲线\n",
    "    if metrics['fpr'] is not None and metrics['tpr'] is not None:\n",
    "        plt.figure()\n",
    "        plt.plot(metrics['fpr'], metrics['tpr'], label='ROC curve (area = %0.2f)' % metrics['roc_auc'])\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "    # 绘制 PR 曲线\n",
    "    if metrics['precision_curve'] is not None and metrics['recall_curve'] is not None:\n",
    "        plt.figure()\n",
    "        plt.plot(metrics['recall_curve'], metrics['precision_curve'], label=f'PR curve (area = {metrics[\"mAP\"]:.2f})')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch(model, train_loader, valid_loader, device, epoch, num_epochs, criterion, pos_label=1):\n",
    "    \"\"\"\n",
    "    评估一个 epoch 的性能，同时评估训练集和验证集\n",
    "\n",
    "    :param model: 训练好的模型\n",
    "    :param train_loader: 训练数据加载器\n",
    "    :param valid_loader: 验证数据加载器\n",
    "    :param device: 设备（CPU 或 GPU）\n",
    "    :param epoch: 当前 epoch\n",
    "    :param num_epochs: 总 epoch 数\n",
    "    :param criterion: 损失函数\n",
    "    :param pos_label: 正类标签，默认为 1\n",
    "    :return: 训练集和验证集的评估结果字典\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    # 评估训练集\n",
    "    train_metrics = evaluate_model(model, train_loader, device, pos_label)\n",
    "    for features, targets in train_loader:\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(features)\n",
    "        if isinstance(outputs, tuple):\n",
    "            outputs = outputs[0]\n",
    "        loss = criterion(outputs, targets)\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # 评估验证集\n",
    "    valid_metrics = evaluate_model(model, valid_loader, device, pos_label)\n",
    "    for features, targets in valid_loader:\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(features)\n",
    "        if isinstance(outputs, tuple):\n",
    "            outputs = outputs[0]\n",
    "        loss = criterion(outputs, targets)\n",
    "        valid_loss += loss.item()\n",
    "    valid_loss /= len(valid_loader)\n",
    "\n",
    "    # 输出评估指标\n",
    "    print(f'Evaluation at epoch : {epoch + 1:03d}/{num_epochs:03d}')\n",
    "    print(f'{{')\n",
    "    print(f'    Loss: train = {train_loss:.4f}; validation = {valid_loss:.4f}')\n",
    "    print(f'    Accuracy: train = {train_metrics[\"accuracy\"] * 100:.2f}%; validation = {valid_metrics[\"accuracy\"] * 100:.2f}%')\n",
    "    print(f'    Precision: train = {train_metrics[\"precision\"]:.2f}; validation = {valid_metrics[\"precision\"]:.2f}')\n",
    "    print(f'    Recall: train = {train_metrics[\"recall\"]:.2f}; validation = {valid_metrics[\"recall\"]:.2f}')\n",
    "    print(f'    F1 Score: train = {train_metrics[\"f1\"]:.2f}; validation = {valid_metrics[\"f1\"]:.2f}')\n",
    "    print(f'}}')\n",
    "\n",
    "    # 更新评估结果字典\n",
    "    train_metrics['loss'] = train_loss\n",
    "    valid_metrics['loss'] = valid_loss\n",
    "\n",
    "    return train_metrics, valid_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
