{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_config import * \n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import data_processing\n",
    "import custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(100))\n",
    "subset = Subset(data_processing.celeba_dataset,indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_loader = DataLoader(subset,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = custom_model.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(mymodel.parameters(), lr=0.001, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './checkpoint.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型和优化器的状态\n",
    "def save_checkpoint(model, optimizer, epoch, loss, checkpoint_path=checkpoint_path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Model saved at epoch {epoch}, with loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, checkpoint_path=checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Loaded model from epoch {epoch} with loss: {loss:.4f}\")\n",
    "    return epoch, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in subset_loader:\n",
    "    print(f'Input images shape: {images.shape}, Labels shape: {labels.shape}')\n",
    "    break  # 只检查第一批"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(mymodel, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    device = torch.device(\"cuda\")\n",
    "    mymodel.to(device)  # 移动模型到 GPU\n",
    "    if os.path.isfile(checkpoint_path):\n",
    "        start_epoch, previous_loss = load_checkpoint(mymodel, optimizer, checkpoint_path=checkpoint_path)\n",
    "    else:\n",
    "        print(\"Starting training from scratch.\")\n",
    "        start_epoch = 0  # 如果没有加载检查点，则从0开始\n",
    "        previous_loss = float('inf')\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    \n",
    "        \n",
    "    for epoch in range(start_epoch,num_epochs):\n",
    "        print(f\"epoch:{epoch}\")\n",
    "        mymodel.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()  # 清空梯度\n",
    "\n",
    "            age_labels = labels[:, 0].float().view(-1, 1)\n",
    "            race_labels = labels[:, 1].float().view(-1, 1)\n",
    "            gender_labels = labels[:, 2].float().view(-1, 1)\n",
    "\n",
    "            \n",
    "            # 前向传播\n",
    "            age_out, race_out, gender_out = mymodel(images)\n",
    "            print(f\"age_out:{age_out}\")\n",
    "            print(f\"age_out shape: {age_out.shape}, age_labels shape: {age_labels.shape}\")\n",
    "                # 计算损失\n",
    "            loss_age = criterion(age_out, age_labels)\n",
    "            loss_race = criterion(race_out, race_labels)\n",
    "            loss_gender = criterion(gender_out, gender_labels)\n",
    "            print(f\"loss_age:{loss_age}\")\n",
    "            total_loss = loss_age + loss_race + loss_gender\n",
    "\n",
    "            total_loss.backward()  # 反向传播\n",
    "            optimizer.step()  # 更新权重\n",
    "\n",
    "            running_loss += total_loss.item()\n",
    "            print(f\"running_loss:{running_loss}\")\n",
    "        \n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"avg_loss:{avg_loss}\")\n",
    "        scheduler.step(avg_loss)  \n",
    "        save_checkpoint(mymodel, optimizer, epoch+1, running_loss/len(train_loader))\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "epoch:0\n",
      "age_out:tensor([[0.7477],\n",
      "        [0.6918],\n",
      "        [0.7328],\n",
      "        [0.7010],\n",
      "        [0.7266],\n",
      "        [0.6808],\n",
      "        [0.7330],\n",
      "        [0.6937],\n",
      "        [0.6943],\n",
      "        [0.7294]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.420623779296875\n",
      "running_loss:1.428068995475769\n",
      "age_out:tensor([[0.7830],\n",
      "        [0.7687],\n",
      "        [0.7447],\n",
      "        [0.7879],\n",
      "        [0.7570],\n",
      "        [0.7435],\n",
      "        [0.7650],\n",
      "        [0.7449],\n",
      "        [0.6847],\n",
      "        [0.7902]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.38567468523979187\n",
      "running_loss:3.112121820449829\n",
      "age_out:tensor([[0.8225],\n",
      "        [0.8612],\n",
      "        [0.8646],\n",
      "        [0.8605],\n",
      "        [0.8630],\n",
      "        [0.8878],\n",
      "        [0.8885],\n",
      "        [0.8642],\n",
      "        [0.8927],\n",
      "        [0.8543]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.5146207213401794\n",
      "running_loss:4.720173120498657\n",
      "age_out:tensor([[0.9287],\n",
      "        [0.9383],\n",
      "        [0.9322],\n",
      "        [0.9179],\n",
      "        [0.9021],\n",
      "        [0.9348],\n",
      "        [0.9556],\n",
      "        [0.9256],\n",
      "        [0.9389],\n",
      "        [0.9265]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.887225329875946\n",
      "running_loss:6.6426472663879395\n",
      "age_out:tensor([[0.7905],\n",
      "        [0.7600],\n",
      "        [0.7619],\n",
      "        [0.7420],\n",
      "        [0.7838],\n",
      "        [0.8026],\n",
      "        [0.7682],\n",
      "        [0.7653],\n",
      "        [0.7925],\n",
      "        [0.7968]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.5277143716812134\n",
      "running_loss:8.619363069534302\n",
      "age_out:tensor([[0.7670],\n",
      "        [0.7559],\n",
      "        [0.7565],\n",
      "        [0.7790],\n",
      "        [0.7580],\n",
      "        [0.7466],\n",
      "        [0.7796],\n",
      "        [0.7886],\n",
      "        [0.7729],\n",
      "        [0.7554]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.637761116027832\n",
      "running_loss:10.543812274932861\n",
      "age_out:tensor([[0.7859],\n",
      "        [0.7797],\n",
      "        [0.7577],\n",
      "        [0.7433],\n",
      "        [0.7520],\n",
      "        [0.7310],\n",
      "        [0.7470],\n",
      "        [0.7601],\n",
      "        [0.7611],\n",
      "        [0.7224]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.6205145716667175\n",
      "running_loss:12.449397802352905\n",
      "age_out:tensor([[0.7259],\n",
      "        [0.7331],\n",
      "        [0.7393],\n",
      "        [0.7245],\n",
      "        [0.7239],\n",
      "        [0.7098],\n",
      "        [0.7114],\n",
      "        [0.7436],\n",
      "        [0.7031],\n",
      "        [0.7108]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.4153594672679901\n",
      "running_loss:14.446189045906067\n",
      "age_out:tensor([[0.7337],\n",
      "        [0.7080],\n",
      "        [0.7140],\n",
      "        [0.6874],\n",
      "        [0.6908],\n",
      "        [0.7233],\n",
      "        [0.7255],\n",
      "        [0.7205],\n",
      "        [0.7107],\n",
      "        [0.7321]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.42613455653190613\n",
      "running_loss:16.185957312583923\n",
      "age_out:tensor([[0.8671],\n",
      "        [0.8712],\n",
      "        [0.8664],\n",
      "        [0.8981],\n",
      "        [0.8635],\n",
      "        [0.8597],\n",
      "        [0.8365],\n",
      "        [0.9030],\n",
      "        [0.8767],\n",
      "        [0.8703]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.3225032687187195\n",
      "running_loss:17.72498607635498\n",
      "avg_loss:1.772498607635498\n",
      "Model saved at epoch 1, with loss: 1.7725\n",
      "Epoch [1/10], Loss: 1.7725\n",
      "epoch:1\n",
      "age_out:tensor([[0.9868],\n",
      "        [0.9908],\n",
      "        [0.9829],\n",
      "        [0.9910],\n",
      "        [0.9853],\n",
      "        [0.9927],\n",
      "        [0.9911],\n",
      "        [0.9885],\n",
      "        [0.9858],\n",
      "        [0.9914]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:1.341423511505127\n",
      "running_loss:2.5178792476654053\n",
      "age_out:tensor([[0.7948],\n",
      "        [0.7981],\n",
      "        [0.7926],\n",
      "        [0.7818],\n",
      "        [0.7555],\n",
      "        [0.7564],\n",
      "        [0.8081],\n",
      "        [0.7800],\n",
      "        [0.7857],\n",
      "        [0.7601]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.3811255693435669\n",
      "running_loss:4.223725318908691\n",
      "age_out:tensor([[0.7031],\n",
      "        [0.7102],\n",
      "        [0.7179],\n",
      "        [0.6890],\n",
      "        [0.6960],\n",
      "        [0.7318],\n",
      "        [0.7317],\n",
      "        [0.7296],\n",
      "        [0.7129],\n",
      "        [0.6857]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.5040306448936462\n",
      "running_loss:6.073652982711792\n",
      "age_out:tensor([[0.6678],\n",
      "        [0.7126],\n",
      "        [0.6840],\n",
      "        [0.7107],\n",
      "        [0.7139],\n",
      "        [0.7023],\n",
      "        [0.6952],\n",
      "        [0.6976],\n",
      "        [0.6649],\n",
      "        [0.6630]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.4395122528076172\n",
      "running_loss:7.852068185806274\n",
      "age_out:tensor([[0.7609],\n",
      "        [0.7260],\n",
      "        [0.7449],\n",
      "        [0.7572],\n",
      "        [0.7589],\n",
      "        [0.7364],\n",
      "        [0.7379],\n",
      "        [0.7423],\n",
      "        [0.7497],\n",
      "        [0.7334]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.5152761340141296\n",
      "running_loss:9.738933563232422\n",
      "age_out:tensor([[0.8062],\n",
      "        [0.8308],\n",
      "        [0.8234],\n",
      "        [0.8356],\n",
      "        [0.8252],\n",
      "        [0.8363],\n",
      "        [0.8089],\n",
      "        [0.8197],\n",
      "        [0.8515],\n",
      "        [0.8391]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.3444582223892212\n",
      "running_loss:11.547266960144043\n",
      "age_out:tensor([[0.8606],\n",
      "        [0.8641],\n",
      "        [0.8904],\n",
      "        [0.8639],\n",
      "        [0.8764],\n",
      "        [0.8775],\n",
      "        [0.8598],\n",
      "        [0.8669],\n",
      "        [0.8695],\n",
      "        [0.9024]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.5300197005271912\n",
      "running_loss:13.299105763435364\n",
      "age_out:tensor([[0.8685],\n",
      "        [0.9047],\n",
      "        [0.8654],\n",
      "        [0.8625],\n",
      "        [0.8585],\n",
      "        [0.8623],\n",
      "        [0.8480],\n",
      "        [0.8576],\n",
      "        [0.8383],\n",
      "        [0.8524]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.6773361563682556\n",
      "running_loss:15.134103178977966\n",
      "age_out:tensor([[0.7572],\n",
      "        [0.7675],\n",
      "        [0.7768],\n",
      "        [0.7946],\n",
      "        [0.7639],\n",
      "        [0.7785],\n",
      "        [0.8079],\n",
      "        [0.7659],\n",
      "        [0.8193],\n",
      "        [0.7839]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.36416465044021606\n",
      "running_loss:16.829179525375366\n",
      "age_out:tensor([[0.8664],\n",
      "        [0.9370],\n",
      "        [0.9307],\n",
      "        [0.8894],\n",
      "        [0.9052],\n",
      "        [0.8412],\n",
      "        [0.8655],\n",
      "        [0.8580],\n",
      "        [0.8920],\n",
      "        [0.9066]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.5748194456100464\n",
      "running_loss:19.495097875595093\n",
      "avg_loss:1.9495097875595093\n",
      "Model saved at epoch 2, with loss: 1.9495\n",
      "Epoch [2/10], Loss: 1.9495\n",
      "epoch:2\n",
      "age_out:tensor([[0.7600],\n",
      "        [0.7589],\n",
      "        [0.7101],\n",
      "        [0.7682],\n",
      "        [0.7519],\n",
      "        [0.7869],\n",
      "        [0.7840],\n",
      "        [0.7632],\n",
      "        [0.7567],\n",
      "        [0.7275]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "age_out shape: torch.Size([10, 1]), age_labels shape: torch.Size([10, 1])\n",
      "loss_age:0.6585328578948975\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmymodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmymodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 44\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(mymodel, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     41\u001b[0m     total_loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# 反向传播\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# 更新权重\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning_loss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(mymodel=mymodel,train_loader=subset_loader,criterion=criterion,optimizer=optimizer,num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facetraining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
