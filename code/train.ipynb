{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import RandomSampler\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:3: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([16, 3, 128, 128])\n",
      "Label batch shape: torch.Size([16])\n",
      "First batch of images: tensor([[[[0.3225, 0.3225, 0.3225,  ..., 0.3225, 0.3194, 0.3194],\n",
      "          [0.3255, 0.3255, 0.3255,  ..., 0.3225, 0.3194, 0.3194],\n",
      "          [0.3255, 0.3255, 0.3255,  ..., 0.3225, 0.3194, 0.3194],\n",
      "          ...,\n",
      "          [0.2562, 0.2592, 0.2562,  ..., 0.5032, 0.4972, 0.4912],\n",
      "          [0.2411, 0.2562, 0.2562,  ..., 0.5123, 0.4972, 0.4972],\n",
      "          [0.2471, 0.2562, 0.2562,  ..., 0.5093, 0.4972, 0.5032]],\n",
      "\n",
      "         [[0.3164, 0.3164, 0.3164,  ..., 0.3164, 0.3134, 0.3134],\n",
      "          [0.3194, 0.3194, 0.3194,  ..., 0.3164, 0.3134, 0.3134],\n",
      "          [0.3194, 0.3194, 0.3194,  ..., 0.3164, 0.3134, 0.3134],\n",
      "          ...,\n",
      "          [0.2532, 0.2562, 0.2532,  ..., 0.5002, 0.4972, 0.4972],\n",
      "          [0.2381, 0.2532, 0.2532,  ..., 0.5093, 0.4942, 0.4972],\n",
      "          [0.2441, 0.2532, 0.2532,  ..., 0.5062, 0.4942, 0.5032]],\n",
      "\n",
      "         [[0.3496, 0.3496, 0.3496,  ..., 0.3496, 0.3466, 0.3466],\n",
      "          [0.3526, 0.3526, 0.3526,  ..., 0.3496, 0.3466, 0.3466],\n",
      "          [0.3526, 0.3526, 0.3526,  ..., 0.3496, 0.3466, 0.3466],\n",
      "          ...,\n",
      "          [0.2712, 0.2742, 0.2712,  ..., 0.5575, 0.5605, 0.5575],\n",
      "          [0.2562, 0.2712, 0.2712,  ..., 0.5635, 0.5575, 0.5635],\n",
      "          [0.2622, 0.2712, 0.2712,  ..., 0.5575, 0.5575, 0.5725]]],\n",
      "\n",
      "\n",
      "        [[[0.9294, 0.9333, 0.9373,  ..., 0.6863, 0.6980, 0.7255],\n",
      "          [0.9294, 0.9333, 0.9373,  ..., 0.6824, 0.6941, 0.7176],\n",
      "          [0.9294, 0.9333, 0.9373,  ..., 0.6902, 0.6980, 0.7176],\n",
      "          ...,\n",
      "          [0.9373, 0.9373, 0.9373,  ..., 0.8196, 0.8157, 0.8157],\n",
      "          [0.9333, 0.9373, 0.9373,  ..., 0.8196, 0.8157, 0.8196],\n",
      "          [0.9294, 0.9333, 0.9333,  ..., 0.8196, 0.8157, 0.8157]],\n",
      "\n",
      "         [[0.9451, 0.9490, 0.9529,  ..., 0.7294, 0.7098, 0.6980],\n",
      "          [0.9451, 0.9490, 0.9529,  ..., 0.7333, 0.7098, 0.6980],\n",
      "          [0.9451, 0.9490, 0.9529,  ..., 0.7294, 0.7098, 0.6980],\n",
      "          ...,\n",
      "          [0.9412, 0.9412, 0.9412,  ..., 0.8235, 0.8196, 0.8196],\n",
      "          [0.9373, 0.9412, 0.9412,  ..., 0.8235, 0.8196, 0.8235],\n",
      "          [0.9333, 0.9373, 0.9373,  ..., 0.8235, 0.8196, 0.8196]],\n",
      "\n",
      "         [[0.9569, 0.9608, 0.9647,  ..., 0.6980, 0.6941, 0.7059],\n",
      "          [0.9569, 0.9608, 0.9647,  ..., 0.6902, 0.6941, 0.7098],\n",
      "          [0.9569, 0.9608, 0.9647,  ..., 0.6863, 0.6902, 0.7020],\n",
      "          ...,\n",
      "          [0.9490, 0.9490, 0.9490,  ..., 0.7922, 0.7882, 0.7882],\n",
      "          [0.9451, 0.9490, 0.9490,  ..., 0.7922, 0.7882, 0.7961],\n",
      "          [0.9412, 0.9451, 0.9451,  ..., 0.7922, 0.7922, 0.7961]]]])\n",
      "First batch of labels: tensor([0, 1])\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=7)\n",
      "  (fc): Linear(in_features=25088, out_features=2, bias=True)\n",
      ")\n",
      "(tensor([[-0.4931, -0.0998]], grad_fn=<AddmmBackward0>), tensor([[0.4029, 0.5971]], grad_fn=<SoftmaxBackward0>))\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import data_processing\n",
    "import custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 3\n",
    "\n",
    "model = custom_model.resnet18(num_classes=10)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "#原先这里选用SGD训练，但是效果很差，换成Adam优化就好了\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = data_processing.test_loader\n",
    "test_loader = data_processing.test_loader\n",
    "train_loader = data_processing.train_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: tensor([0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1])\n",
      "Unique values in labels: tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in test_loader:\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Unique values in labels:\", labels.unique())\n",
    "    break  # 只查看一个批次的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/003 | Batch 0000/1248 | Cost: 2.3691\n",
      "Epoch: 001/003 | Batch 0500/1248 | Cost: 0.7010\n",
      "Epoch: 001/003 | Batch 1000/1248 | Cost: 0.2624\n",
      "Epoch: 001/003 Train Acc.: 86.33% | Validation Acc.: 85.70%\n",
      "Time elapsed: 15.65 min\n",
      "Epoch: 002/003 | Batch 0000/1248 | Cost: 0.8019\n",
      "Epoch: 002/003 | Batch 0500/1248 | Cost: 0.5110\n",
      "Epoch: 002/003 | Batch 1000/1248 | Cost: 0.3778\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 28\u001b[0m\n\u001b[0;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (features, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m### PREPARE MINIBATCH\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m### FORWARD AND BACK PROP\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def compute_accuracy_and_loss(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    cross_entropy = 0.\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        cross_entropy += F.cross_entropy(logits, targets).item()\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100, cross_entropy/num_examples\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "train_acc_lst, valid_acc_lst = [], []\n",
    "train_loss_lst, valid_loss_lst = [], []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "    \n",
    "        ### PREPARE MINIBATCH\n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 500:\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:04d}/{len(train_loader):04d} |' \n",
    "                   f' Cost: {cost:.4f}')\n",
    "\n",
    "    # no need to build the computation graph for backprop when computing accuracy\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        train_acc, train_loss = compute_accuracy_and_loss(model, train_loader, device=DEVICE)\n",
    "        valid_acc, valid_loss = compute_accuracy_and_loss(model, valid_loader, device=DEVICE)\n",
    "        train_acc_lst.append(train_acc)\n",
    "        valid_acc_lst.append(valid_acc)\n",
    "        train_loss_lst.append(train_loss)\n",
    "        valid_loss_lst.append(valid_loss)\n",
    "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Train Acc.: {train_acc:.2f}%'\n",
    "              f' | Validation Acc.: {valid_acc:.2f}%')\n",
    "        \n",
    "    elapsed = (time.time() - start_time)/60\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')\n",
    "  \n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facetraining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
